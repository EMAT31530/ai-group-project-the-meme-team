Sensors: 13 (3*position, 4*rotation, 3*velocity, 3*angular velocity)
Actuators: 3 (joystick, throttle - mapping extended to [0,1.1] followed by clamping)
DOF: Full DOF
Drag: 0.1
Angular Drag: 0.1

Reward Shaping:
Penalty for leaving environment = -10f
Penalty for missing target = -5f
Reward for hitting target = 5f

Config File:
rocketlander_config_v4_DAR_Curriculum
No. of steps = 1e6
Corrected curriculum learning - linked to target behaviour

Experimental Results / Observations:
Promising performance - clearly learnt some controls.
Behaviour largely spirals, but does seem to seek target IF close enough.
Immediate thoughts for improvement include raising spawn height, so longer to react to ground (appears to make several last minute saves / falls)
Could also increase number of steps and / or change rate of curriculum change