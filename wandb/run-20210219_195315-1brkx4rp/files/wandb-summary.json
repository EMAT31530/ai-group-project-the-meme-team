{"Policy/Entropy": 1.4189387559890747, "Policy/Extrinsic Value Estimate": 0.2143772542476654, "Environment/Episode Length": 99.0, "Is Training": 1.0, "_runtime": 5, "_timestamp": 1613764400, "_step": 56530, "Environment/Cumulative Reward": -7.081079006195068, "Policy/Extrinsic Reward": -7.081079006195068, "Losses/Policy Loss": 0.009658319875597954, "Losses/Value Loss": 0.4194982051849365, "Policy/Learning Rate": 0.0002830433950293809, "Policy/Epsilon": 0.47739121317863464, "Policy/Beta": 0.0009440432186238468}