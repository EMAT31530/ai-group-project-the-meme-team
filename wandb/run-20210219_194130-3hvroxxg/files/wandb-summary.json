{"Policy/Entropy": 0.023441853001713753, "_runtime": 5, "_timestamp": 1613763696, "_step": 56530, "Policy/Extrinsic Value Estimate": 0.007905155420303345, "Environment/Episode Length": 0.01370302028954029, "Is Training": 0.017632970586419106, "Environment/Cumulative Reward": 0.016433950513601303, "Policy/Extrinsic Reward": 0.03248324990272522, "Losses/Policy Loss": 0.020625347271561623, "Losses/Value Loss": 0.007801851723343134, "Policy/Learning Rate": 0.010395958088338375, "Policy/Epsilon": 0.00781962089240551, "Policy/Beta": 0.0009440432186238468}